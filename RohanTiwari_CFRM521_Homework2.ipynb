{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "center",
    "id": "SJNkHyZ3cWTN"
   },
   "source": [
    "<h1>\n",
    "<center>CFRM 421/521, Spring 2022</center>\n",
    "</h1>\n",
    "\n",
    "<h1>\n",
    "<center>Rohan Tiwari</center>\n",
    "</h1>\n",
    "\n",
    "<h1>\n",
    "<center>Homework 2</center>\n",
    "</h1>\n",
    "\n",
    "* **Due: Monday, May 2, 2022, 11:59 PM**\n",
    "\n",
    "\n",
    "* Total marks: 41\n",
    "\n",
    "\n",
    "* Late submissions are allowed, but a 20% penalty per day applies. Your last submission is considered for calculating the penalty.\n",
    "\n",
    "\n",
    "*  Use this Jupyter notebook as a template for your solutions. **Your solution must be submitted as one Jupyter notebook on Canvas and one PDF file on Gradescope.** The notebook must be already run, that is, make sure that you have run all your code, save the notebook, and then when you reopen the notebook, checked that all output appears as expected. You are allowed to use code from the textbook, textbook website, or lecture notes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3RyeQ5M9cWTP"
   },
   "source": [
    "# 1. Random forest for time series data [13 marks]\n",
    "\n",
    "In this question you will work with the NYSE dataset. Only 3 time series in this dataset will be use: `DJ_return` ($a_t$), `log_volatility` ($b_t$), and `log_volume` ($c_t$). Download the data as a csv file from [Canvas](https://canvas.uw.edu/files/91091313/download?download_frd=1). The data was originally obtained from the R library ISLR2, and you can read the documentation for the dataset [here](https://cran.rstudio.com/web/packages/ISLR2/ISLR2.pdf), which explains the meaning of the variables.\n",
    "\n",
    "You want to predict the 1-step ahead value of `log_volume` $c_{t+1}$ using the previous values of this variable and the other two variables (`DJ_return` and `log_volatility`) up to 5 lags. So the features are $c_{t},\\dots,c_{t-4},b_{t},\\dots,b_{t-4},a_{t},\\dots,a_{t-4}$.\n",
    "\n",
    "If the data is stored in a file named `NYSE.csv` in your working directory, then loading the data can be done using the code below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "GKfSZYUNcWTP",
    "outputId": "5f37683c-4ba7-4c1b-d47e-2c30cfb78707"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>DJ_return</th>\n",
       "      <th>log_volume</th>\n",
       "      <th>log_volatility</th>\n",
       "      <th>train</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1962-12-03</td>\n",
       "      <td>mon</td>\n",
       "      <td>-0.004461</td>\n",
       "      <td>0.032573</td>\n",
       "      <td>-13.127403</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1962-12-04</td>\n",
       "      <td>tues</td>\n",
       "      <td>0.007813</td>\n",
       "      <td>0.346202</td>\n",
       "      <td>-11.749305</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1962-12-05</td>\n",
       "      <td>wed</td>\n",
       "      <td>0.003845</td>\n",
       "      <td>0.525306</td>\n",
       "      <td>-11.665609</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1962-12-06</td>\n",
       "      <td>thur</td>\n",
       "      <td>-0.003462</td>\n",
       "      <td>0.210182</td>\n",
       "      <td>-11.626772</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1962-12-07</td>\n",
       "      <td>fri</td>\n",
       "      <td>0.000568</td>\n",
       "      <td>0.044187</td>\n",
       "      <td>-11.728130</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date day_of_week  DJ_return  log_volume  log_volatility  train\n",
       "0  1962-12-03         mon  -0.004461    0.032573      -13.127403   True\n",
       "1  1962-12-04        tues   0.007813    0.346202      -11.749305   True\n",
       "2  1962-12-05         wed   0.003845    0.525306      -11.665609   True\n",
       "3  1962-12-06        thur  -0.003462    0.210182      -11.626772   True\n",
       "4  1962-12-07         fri   0.000568    0.044187      -11.728130   True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "data = pd.read_csv(\"NYSE.csv\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2TFAell6cWTQ"
   },
   "source": [
    "## (a) [3 marks]\n",
    "\n",
    "Create the feature matrix `X` and the target variable `y`. Print at least the first 2 rows of `X` and `y` (it is acceptable that not every element of the rows are printed)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LgPHRvhYcWTQ"
   },
   "source": [
    "**[Add your solution here]**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 363
    },
    "id": "STnkdoWhTXuq",
    "outputId": "9ed256c7-b8b8-4407-b481-ca9b98ac67c9"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DJ_return</th>\n",
       "      <th>log_volume</th>\n",
       "      <th>log_volatility</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.004461</td>\n",
       "      <td>0.032573</td>\n",
       "      <td>-13.127403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.007813</td>\n",
       "      <td>0.346202</td>\n",
       "      <td>-11.749305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.003845</td>\n",
       "      <td>0.525306</td>\n",
       "      <td>-11.665609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.003462</td>\n",
       "      <td>0.210182</td>\n",
       "      <td>-11.626772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000568</td>\n",
       "      <td>0.044187</td>\n",
       "      <td>-11.728130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-0.010824</td>\n",
       "      <td>0.133246</td>\n",
       "      <td>-10.872526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.000124</td>\n",
       "      <td>-0.011528</td>\n",
       "      <td>-10.977797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.003358</td>\n",
       "      <td>0.001607</td>\n",
       "      <td>-11.012360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>-0.003296</td>\n",
       "      <td>-0.106437</td>\n",
       "      <td>-11.047108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.004469</td>\n",
       "      <td>-0.138269</td>\n",
       "      <td>-11.022063</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   DJ_return  log_volume  log_volatility\n",
       "0  -0.004461    0.032573      -13.127403\n",
       "1   0.007813    0.346202      -11.749305\n",
       "2   0.003845    0.525306      -11.665609\n",
       "3  -0.003462    0.210182      -11.626772\n",
       "4   0.000568    0.044187      -11.728130\n",
       "5  -0.010824    0.133246      -10.872526\n",
       "6   0.000124   -0.011528      -10.977797\n",
       "7   0.003358    0.001607      -11.012360\n",
       "8  -0.003296   -0.106437      -11.047108\n",
       "9   0.004469   -0.138269      -11.022063"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = data.drop(['date', 'day_of_week', 'train'], axis=1)\n",
    "data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TMX0WZC1N661",
    "outputId": "fc4fb08b-6251-4484-f24d-58a45ad26c71"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6046, 15)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import numpy as np\n",
    "# def ts_split_X(ts, feature_steps=5, target_steps=1):\n",
    "#     n_obs = len(ts) - feature_steps - target_steps + 1\n",
    "#     X = np.array([ts[idx:idx + feature_steps] for idx in range(n_obs)])\n",
    "#     #y = np.array([ts[idx + feature_steps:idx + feature_steps + target_steps]\n",
    "#                   #for idx in range(n_obs)])\n",
    "#     return X\n",
    "\n",
    "# # X_train = data.iloc[:4281, :]\n",
    "# # X1_train = ts_split_X(X_train['DJ_return'])\n",
    "# # X2_train = ts_split_X(X_train['log_volume'])\n",
    "# # X3_train = ts_split_X(X_train['log_volatility'])\n",
    "# # X = np.column_stack((X1_train, X2_train, X3_train))\n",
    "\n",
    "# # X.shape\n",
    "\n",
    "# #full datset\n",
    "# X1_train = ts_split_X(data['DJ_return'])\n",
    "# X2_train = ts_split_X(data['log_volume'])\n",
    "# X3_train = ts_split_X(data['log_volatility'])\n",
    "# X = np.column_stack((X1_train, X2_train, X3_train))\n",
    "import numpy as np\n",
    "def ts_split(ts, feature_steps=5, target_steps=1):\n",
    "    n_obs = len(ts) - feature_steps - target_steps + 1\n",
    "    X = np.array([ts[idx:idx + feature_steps] for idx in range(n_obs)])\n",
    "    y = np.array([ts[idx + feature_steps:idx + feature_steps + target_steps]\n",
    "                  for idx in range(n_obs)])\n",
    "    return X, y\n",
    "\n",
    "X1 = ts_split(data['log_volume'])[0]\n",
    "X2 = ts_split(data['log_volatility'])[0]\n",
    "X3 = ts_split(data['DJ_return'])[0]\n",
    "y = ts_split(data['log_volume'])[1]\n",
    "\n",
    "X =  np.hstack((X1, X2, X3))\n",
    "\n",
    "\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MZ-50I8XZTfH",
    "outputId": "cf08bad8-81b3-4ae7-fb62-bac800b70adf"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 3.25730000e-02,  3.46202000e-01,  5.25306000e-01,\n",
       "         2.10182000e-01,  4.41870000e-02, -1.31274026e+01,\n",
       "        -1.17493047e+01, -1.16656090e+01, -1.16267724e+01,\n",
       "        -1.17281302e+01, -4.46100000e-03,  7.81300000e-03,\n",
       "         3.84500000e-03, -3.46200000e-03,  5.68000000e-04],\n",
       "       [ 3.46202000e-01,  5.25306000e-01,  2.10182000e-01,\n",
       "         4.41870000e-02,  1.33246000e-01, -1.17493047e+01,\n",
       "        -1.16656090e+01, -1.16267724e+01, -1.17281302e+01,\n",
       "        -1.08725263e+01,  7.81300000e-03,  3.84500000e-03,\n",
       "        -3.46200000e-03,  5.68000000e-04, -1.08240000e-02]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[:2,]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gdMZ_IvCKqTr",
    "outputId": "cee9251d-f078-4645-97a7-7f66b08eed0b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6046, 1)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import numpy as np\n",
    "# def ts_split_y(ts, feature_steps=5, target_steps=1):\n",
    "#     n_obs = len(ts) - feature_steps - target_steps + 1\n",
    "#    # X = np.array([ts[idx:idx + feature_steps] for idx in range(n_obs)])\n",
    "#     y = np.array([ts[idx + feature_steps:idx + feature_steps + target_steps]\n",
    "#                   for idx in range(n_obs)])\n",
    "#     return y\n",
    "\n",
    "\n",
    "# # y = ts_split_y(X_train['log_volume'])\n",
    "\n",
    "# y = ts_split_y(data['log_volume'])\n",
    "\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GhnG6_OgLHCY",
    "outputId": "130e3ab7-2776-4e50-fa1d-c2d34ccc3f6d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.133246],\n",
       "       [-0.011528]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[:2, ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OYbkjx-VcWTQ"
   },
   "source": [
    "## (b)  [4 marks]\n",
    "\n",
    "Consider fitting a random forest to predict the 1-step ahead value of `log_volume`. The random forest must include the argument `random_state=42`, and it is useful to also include `n_jobs=-1` (you can use `n_job=-1` throughout this homework wherever it is avaliable). Use 3-fold time series CV, with the test set split 50% into a validation set and 50% into the actual test set, to tune the hyperparameters `n_estimators` taking the values  100, 500, 750, and the cost-complexity pruning parameter $\\alpha$ taking the values $10^{-k}$, $k=0,1,\\dots,9$. The performance measure is RMSE. Report the best hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "iIL441Oy0zfo"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "\n",
    "n_estimators_list = [100, 500, 750]\n",
    "alpha_list = [10**0, 10**-1, 10**-2,10**-3, 10**-4, 10**-5, 10**-6, 10**-7, 10**-8, 10**-9]\n",
    "\n",
    "def time_series_valid_test(X, y, n_split, valid_or_test, optimal_par=None):\n",
    "    tscv = TimeSeriesSplit(n_splits=n_split)\n",
    "    rf_rmse = []\n",
    "    i = 0\n",
    "    series_len = y.size\n",
    "    for train_index, test_index in tscv.split(X):\n",
    "        i += 1\n",
    "        # Break test set into 50% validation set, 50% test set\n",
    "        break_test_ind = int(test_index[0] + 0.5*(test_index[-1]-test_index[0]))\n",
    "        valid_index = np.array(list(range(test_index[0],break_test_ind)))\n",
    "        test_index = np.array(list(range(break_test_ind,test_index[-1])))\n",
    "\n",
    "        # Split\n",
    "        X_train, X_valid, X_test = X[train_index], X[valid_index], X[test_index]\n",
    "        y_train, y_valid, y_test = y[train_index], y[valid_index], y[test_index]\n",
    "\n",
    "        # Tuning\n",
    "        if valid_or_test == \"valid\":\n",
    "            for ccp_alpha in alpha_list:\n",
    "                for n_estimators in n_estimators_list:\n",
    "                    model_rf = RandomForestRegressor(random_state=42, \n",
    "                               ccp_alpha=ccp_alpha, n_estimators=n_estimators)\n",
    "                    model_rf.fit(X_train, y_train.ravel())\n",
    "                    y_val_rf = model_rf.predict(X_valid)\n",
    "                    rf_rmse.append(np.sqrt(mean_squared_error(y_valid, y_val_rf)))\n",
    "        \n",
    "        # Evalulate on test set\n",
    "        if valid_or_test == \"test\":\n",
    "            model_rf = RandomForestRegressor(random_state=42, \n",
    "                       ccp_alpha=optimal_par[0], n_estimators=optimal_par[1])\n",
    "            model_rf.fit(X_train, y_train.ravel())\n",
    "            y_test_rf = model_rf.predict(X_test)\n",
    "            rf_rmse.append(np.sqrt(mean_squared_error(y_test, y_test_rf)))\n",
    "            \n",
    "            # Plot the prediction for the last CV fold\n",
    "            if i == n_split:\n",
    "                plt.plot(range(series_len-test_index.size,series_len),\n",
    "                         y_test_rf, label=\"1-steps ahead prediction\")\n",
    "                plt.plot(range(series_len-test_index.size,series_len),\n",
    "                         y_test, label=\"True value\")\n",
    "                plt.legend(loc=\"upper left\")\n",
    "    \n",
    "    # Average RMSE over CV folds\n",
    "    if valid_or_test == \"valid\":\n",
    "        rf_rmse = np.mean(np.array(rf_rmse).reshape(\n",
    "            n_split, len(alpha_list)*len(n_estimators_list)), axis=0)\n",
    "        return rf_rmse\n",
    "    if valid_or_test == \"test\":\n",
    "        rf_rmse = np.mean(rf_rmse)\n",
    "        return rf_rmse, y_test_rf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NbbG31Jck-TA",
    "outputId": "e7addbc2-3276-4fec-9779-cf73a7f27b45"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['(ccp_alpha, n_estimators):', [1, 100]]\n",
      "0.2358102502325389\n",
      "['(ccp_alpha, n_estimators):', [1, 500]]\n",
      "0.23583279057420017\n",
      "['(ccp_alpha, n_estimators):', [1, 750]]\n",
      "0.23582412722547763\n",
      "['(ccp_alpha, n_estimators):', [0.1, 100]]\n",
      "0.2358102502325389\n",
      "['(ccp_alpha, n_estimators):', [0.1, 500]]\n",
      "0.23583279057420017\n",
      "['(ccp_alpha, n_estimators):', [0.1, 750]]\n",
      "0.23582412722547763\n",
      "['(ccp_alpha, n_estimators):', [0.01, 100]]\n",
      "0.1931776501341703\n",
      "['(ccp_alpha, n_estimators):', [0.01, 500]]\n",
      "0.19289278821198516\n",
      "['(ccp_alpha, n_estimators):', [0.01, 750]]\n",
      "0.1928692930007393\n",
      "['(ccp_alpha, n_estimators):', [0.001, 100]]\n",
      "0.1742571823815323\n",
      "['(ccp_alpha, n_estimators):', [0.001, 500]]\n",
      "0.1741139415851224\n",
      "['(ccp_alpha, n_estimators):', [0.001, 750]]\n",
      "0.17402380547187205\n",
      "['(ccp_alpha, n_estimators):', [0.0001, 100]]\n",
      "0.16132624100564838\n",
      "['(ccp_alpha, n_estimators):', [0.0001, 500]]\n",
      "0.16110479140675354\n",
      "['(ccp_alpha, n_estimators):', [0.0001, 750]]\n",
      "0.16118102970655726\n",
      "['(ccp_alpha, n_estimators):', [1e-05, 100]]\n",
      "0.1608409994589393\n",
      "['(ccp_alpha, n_estimators):', [1e-05, 500]]\n",
      "0.1603776351406714\n",
      "['(ccp_alpha, n_estimators):', [1e-05, 750]]\n",
      "0.1604525452413842\n",
      "['(ccp_alpha, n_estimators):', [1e-06, 100]]\n",
      "0.16114731686916905\n",
      "['(ccp_alpha, n_estimators):', [1e-06, 500]]\n",
      "0.16053001991047358\n",
      "['(ccp_alpha, n_estimators):', [1e-06, 750]]\n",
      "0.16061237168794265\n",
      "['(ccp_alpha, n_estimators):', [1e-07, 100]]\n",
      "0.1612304117776293\n",
      "['(ccp_alpha, n_estimators):', [1e-07, 500]]\n",
      "0.1605466237281532\n",
      "['(ccp_alpha, n_estimators):', [1e-07, 750]]\n",
      "0.1606247525940114\n",
      "['(ccp_alpha, n_estimators):', [1e-08, 100]]\n",
      "0.1612330205584586\n",
      "['(ccp_alpha, n_estimators):', [1e-08, 500]]\n",
      "0.16054509429255723\n",
      "['(ccp_alpha, n_estimators):', [1e-08, 750]]\n",
      "0.16062537881149105\n",
      "['(ccp_alpha, n_estimators):', [1e-09, 100]]\n",
      "0.16123507642301327\n",
      "['(ccp_alpha, n_estimators):', [1e-09, 500]]\n",
      "0.16054554369906407\n",
      "['(ccp_alpha, n_estimators):', [1e-09, 750]]\n",
      "0.16062560069863865\n",
      "Minimum rmse is:  0.1603776351406714\n"
     ]
    }
   ],
   "source": [
    "# rf_rmse = time_series_valid_test(X_test, y_test, 3, \"valid\")\n",
    "rf_rmse = time_series_valid_test(X, y, 3, \"valid\")\n",
    "ind = 0\n",
    "min = 100\n",
    "for ccp_alpha in alpha_list:\n",
    "        for n_estimators in n_estimators_list:\n",
    "            print([\"(ccp_alpha, n_estimators):\",[ccp_alpha, n_estimators]])\n",
    "            print(rf_rmse[ind])\n",
    "            if rf_rmse[ind] < min:\n",
    "              min = rf_rmse[ind]\n",
    "            ind += 1\n",
    "\n",
    "print(\"Minimum rmse is: \", min)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WLK1fXsGA0xY"
   },
   "source": [
    "Best hyperparameters are ['(ccp_alpha, n_estimators):', [1e-05, 500]]\n",
    " that minimize the rmse.  Minimum rmse is 0.1603776351406714"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a-sOkCs8cWTR"
   },
   "source": [
    "**[Add your solution here]**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Pi7g3krvcWTR"
   },
   "source": [
    "## (c)  [2 marks]\n",
    "\n",
    "Using the same time series split as in (b), compute the RMSE of the best fitting model on the test set, and include a plot of the true values and predicted values on the test set of the last fold (the fold closest to the current time) of the CV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 537
    },
    "id": "s5UmmqSyCCv_",
    "outputId": "f2c55bdd-a8b2-4f2f-a522-069e94c443fb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.18693224107605255"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "rf_rmse, y_test_rf = time_series_valid_test(X, y, 3, \"test\",  [1e-05, 500])\n",
    "\n",
    "rf_rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2U0TYtaXcWTR"
   },
   "source": [
    "**[Add your solution here]**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AUZEMKf_cWTR"
   },
   "source": [
    "## (d) [2 marks]\n",
    "\n",
    "It is often useful to check that your model is not worse than a very simple method of prediction. Compute the RMSE of a model that simply predicts the 1-step ahead value of `log_volume` $c_{t+1}$ as the current value $c_t$, and compare this to the best fitting random forest model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "n4KPXanQEgcj",
    "outputId": "29af7537-70a3-4e39-c328-3629b5300ab1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.18890174010847652"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from scipy.ndimage.interpolation import shift\n",
    "\n",
    "\n",
    "\n",
    "# X_simple = data['log_volume'].to_numpy()\n",
    "# y_simple = data['log_volume'].to_numpy()\n",
    "\n",
    "y_temp = data['log_volume']\n",
    "y_pred = data['log_volume']\n",
    "\n",
    "np.sqrt(mean_squared_error(y_pred[:len(y_pred)-1], y_temp[1:]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SgDTlzkjl92h"
   },
   "source": [
    "The best fitting random forest model does better than the simple method of prediction as it has a lower rmse. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BZ6XoRjBcWTS"
   },
   "source": [
    "**[Add your solution here]**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rWBKk6UzcWTS"
   },
   "source": [
    "## (e) [2 marks]\n",
    "\n",
    "Compute the feature importances of the best fitting model. Which feature is the most important and what is its feature importance value?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kJCxBvBTmnER",
    "outputId": "0a0f7a35-6fae-4c8a-8046-086ae87070f3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.05909577, 0.06289336, 0.04348415, 0.0371032 , 0.52852018,\n",
       "       0.01550909, 0.01223347, 0.01108555, 0.01269354, 0.0138164 ,\n",
       "       0.03372512, 0.02977974, 0.03705288, 0.03899174, 0.06401581])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "model_rf = RandomForestRegressor(random_state=42, \n",
    "                       ccp_alpha=1e-05, n_estimators=500, n_jobs=-1)\n",
    "model_rf.fit(X,y.ravel())\n",
    "model_rf.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.5285201844665299"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "feat_importances = pd.Series(model_rf.feature_importances_)\n",
    "feat_importances.plot(kind='barh')\n",
    "plt.title(\"Important features\")\n",
    "plt.show()\n",
    "max(feat_importances)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YOtdImuEn5nD"
   },
   "source": [
    "The most important feature is the log_volume at t-4.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zVKO1Jb_cWTS"
   },
   "source": [
    "**[Add your solution here]**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5yQ6lSQbcWTS"
   },
   "source": [
    "# 2. SVM classification and regression [11 marks]\n",
    "\n",
    "## (a) [2 marks]\n",
    "\n",
    "In this question, a SVM is used for classification for the MNIST dataset. The following code loads the MNIST dataset, creates the test set, and to reduce training time, takes a random sample of 2000 points from the full training set to use as your actual training set stored in `X` and `y`. Do not shuffle the data and do not use a standard scaler.\n",
    "\n",
    "Hint: Reading the solution to Question 9 in the Chapter 5 [Jupyter notebook](https://github.com/ageron/handson-ml2/blob/master/05_support_vector_machines.ipynb) on the textbook website may help with this question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "v66Q0MJxcWTS"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib as mlp\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.datasets import fetch_openml\n",
    "mnist = fetch_openml('mnist_784', version=1, as_frame=False, cache=True)\n",
    "mnist.target = mnist.target.astype(np.int8)\n",
    "X_train = mnist[\"data\"][:60000]\n",
    "X_test  = mnist[\"data\"][60000:]\n",
    "y_train = mnist[\"target\"][:60000]\n",
    "y_test  = mnist[\"target\"][60000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gVjDEEKocWTT",
    "outputId": "5359a616-7821-4a8f-9321-5f66eb466d6f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2000, 784)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "N = 2000\n",
    "split_obj = StratifiedShuffleSplit(n_splits=1,\n",
    "                               test_size=N/60000, random_state=42)\n",
    "for other_idx, subsample_idx in split_obj.split(X_train, y_train):\n",
    "    X = X_train[subsample_idx]\n",
    "    y = y_train[subsample_idx]\n",
    "\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Xnn01AeDcWTT"
   },
   "source": [
    "**Task:** Consider fitting the linear SVM classifier (`LinearSVC`) with `max_iter=50000`. For this model, optimize the hyperparameter $C$ using 3-fold CV over the values $10^{-k}$, $k=0,1,\\dots,9$, where the performance measure is accuracy. What is the best $C$ and what is the accuracy in this case?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GlkvWgFwMVRO",
    "outputId": "62868ed6-96ce-4af0-8d14-3aea29efcdb4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best value of hyperparameters is:  LinearSVC(C=1e-07, max_iter=50000)\n",
      "accuracy is:  0.8624974299636969\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.svm import LinearSVC\n",
    "import numpy as np\n",
    " \n",
    "params = {\"C\": [10**0, 10**-1, 10**-2,10**-3, 10**-4, 10**-5, 10**-6, 10**-7, 10**-8, 10**-9]}\n",
    "rd_search = RandomizedSearchCV(LinearSVC(max_iter=50000), params,random_state=42, cv=3,scoring=\"accuracy\", n_jobs=-1)\n",
    "rd_search.fit(X,y)\n",
    "\n",
    "print(\"best value of hyperparameters is: \", rd_search.best_estimator_)\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "y_pred = rd_search.best_estimator_.predict(X)\n",
    "print(\"accuracy is: \", rd_search.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5jvN7YaacWTT"
   },
   "source": [
    "**[Add your solution here]**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jfBikqyHcWTT"
   },
   "source": [
    "## (b) [2 marks]\n",
    "\n",
    "**Task:** Now consider fitting a SVM with a Gaussian RBF kernel and `max_iter=50000`. For this model, optimize the hyperparameters $C$ over the distrbution `uniform(1,10)` and $\\gamma$ over the distribution `reciprocal(0.001, 0.1)` with 10 random samples. Again, use 3-fold CV and the performance measure is accuracy. What are the best hyperparameters and what is the accuracy in this case?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qPWybvdPAI6b",
    "outputId": "cbc9036d-f41a-4738-f13d-305af81cff17"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best value of hyperparameters is:  SVC(C=4.745401188473625, gamma=0.07969454818643928, max_iter=50000)\n",
      "accuracy is:  0.11250005627816723\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import reciprocal, uniform\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "params = {\"gamma\": reciprocal(0.001, 0.1), \"C\": uniform(1, 10)}\n",
    "svm_rd_search_cv = RandomizedSearchCV(SVC(kernel='rbf', max_iter=50000), params, random_state=42, cv=3,scoring=\"accuracy\")\n",
    "svm_rd_search_cv.fit(X, y)\n",
    "print(\"best value of hyperparameters is: \", svm_rd_search_cv.best_estimator_)\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "y_pred = svm_rd_search_cv.best_estimator_.predict(X)\n",
    "print(\"accuracy is: \", svm_rd_search_cv.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Hi3knjj1cWTU"
   },
   "source": [
    "**[Add your solution here]**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jdvV4zBQcWTU"
   },
   "source": [
    "## (c) [2 mark]\n",
    "\n",
    "**Task:** Choose the best model in (a) and (b). Then for this model, evaluate the accuracy on the test set, which is stored in `X_test` and `y_test`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "l4l2qFeyG__C"
   },
   "source": [
    "Best model is Linear SVC due to better accuracy score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "c6rGhoFpHEdh",
    "outputId": "acbd90b5-b6cb-4372-d92c-34181340a8e1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy is:  0.8873\n"
     ]
    }
   ],
   "source": [
    "y_pred_test = rd_search.best_estimator_.predict(X_test)\n",
    "print(\"accuracy is: \", accuracy_score(y_test, y_pred_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3URRxU79cWTU"
   },
   "source": [
    "**[Add your solution here]**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FsH5-h5IcWTU"
   },
   "source": [
    "## (d) [3 marks]\n",
    "\n",
    "Consider the California housing data from Homework 1 using the same training and test set there. The data is obtained using the code below, which comes from Homework 1, and the training set is stored in `X` and `y`. Do not shuffle the data.\n",
    "\n",
    "Hint: Reading the solution to Question 10 in the Chapter 5 [Jupyter notebook](https://github.com/ageron/handson-ml2/blob/master/05_support_vector_machines.ipynb) on the textbook website may help with this question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0iGJeXWTcWTU"
   },
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "\n",
    "\n",
    "import os\n",
    "import tarfile\n",
    "from six.moves import urllib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "HOUSING_PATH = os.path.join(\"datasets\", \"housing\")\n",
    "\n",
    "def fetch_housing_data(housing_url, housing_path=HOUSING_PATH):\n",
    "    if not os.path.isdir(housing_path):\n",
    "        os.makedirs(housing_path)\n",
    "    tgz_path = os.path.join(housing_path, \"housing.tgz\")\n",
    "    urllib.request.urlretrieve(housing_url, tgz_path)\n",
    "    housing_tgz = tarfile.open(tgz_path)\n",
    "    housing_tgz.extractall(path=housing_path)\n",
    "    housing_tgz.close()\n",
    "\n",
    "def load_housing_data(housing_path=HOUSING_PATH):\n",
    "    csv_path = os.path.join(housing_path, \"housing.csv\")\n",
    "    return pd.read_csv(csv_path)\n",
    "\n",
    "HOUSING_URL = (\"https://raw.githubusercontent.com/ageron/\"+\n",
    "               \"handson-ml2/master/datasets/housing/housing.tgz\")\n",
    "fetch_housing_data(HOUSING_URL)\n",
    "data = load_housing_data()\n",
    "\n",
    "data[\"income_cat\"] = np.ceil(data[\"median_income\"] / 1.5)\n",
    "data[\"income_cat\"].where(data[\"income_cat\"] < 5, 5.0, inplace=True)\n",
    "split = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=42)\n",
    "for train_index, test_index in split.split(data, data[\"income_cat\"]):\n",
    "    strat_train_set = data.loc[train_index]\n",
    "    strat_test_set = data.loc[test_index]\n",
    "for set_ in (strat_train_set, strat_test_set):\n",
    "    set_.drop(\"income_cat\", axis=1, inplace=True)\n",
    "X_raw = strat_train_set.drop(\"median_house_value\", axis=1)\n",
    "y = strat_train_set[\"median_house_value\"].copy()\n",
    "\n",
    "num_pipeline = Pipeline([\n",
    "        ('imputer', SimpleImputer(strategy=\"median\")),\n",
    "        ('std_scaler', StandardScaler()),\n",
    "    ])\n",
    "num_features = X_raw.drop(\"ocean_proximity\", axis=1)\n",
    "num_attribs = list(num_features)\n",
    "cat_attribs = [\"ocean_proximity\"]\n",
    "full_pipeline = ColumnTransformer([\n",
    "        (\"num\", num_pipeline, num_attribs),\n",
    "        (\"cat\", OneHotEncoder(), cat_attribs),\n",
    "    ])\n",
    "\n",
    "X = full_pipeline.fit_transform(X_raw)\n",
    "X_test_raw = strat_test_set.drop(\"median_house_value\", axis=1)\n",
    "y_test = strat_test_set[\"median_house_value\"].copy()\n",
    "X_test = full_pipeline.transform(X_test_raw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6N5DbdhfcWTV"
   },
   "source": [
    "**Task:** Consider SVM regression with a Gaussian RBF kernel and a sigmoid kernel with `max_iter=50000`. For both models, use randomized search to choose good hyperparameter values for `C` and `gamma`, and set the arguement `random_state=42`. For both models, optimize the hyperparameters $C$ over the distrbution `uniform(1,10)` and $\\gamma$ over the distribution `reciprocal(0.001, 0.1)` with 10 random samples. Again, use 3-fold CV and the performance measure is MSE. What are the best hyperparameters and what is the MSE in this case?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LTXHO9tsJVm9",
    "outputId": "039be2b9-a718-460f-adf2-1363679221e6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=3, estimator=SVR(max_iter=50000), n_jobs=-1,\n",
       "                   param_distributions={'C': <scipy.stats._distn_infrastructure.rv_frozen object at 0x7f0cc6bb1a90>,\n",
       "                                        'gamma': <scipy.stats._distn_infrastructure.rv_frozen object at 0x7f0cc6bb1fd0>},\n",
       "                   random_state=42, scoring='neg_mean_squared_error')"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVR\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats import reciprocal, uniform\n",
    "\n",
    "params = {\"gamma\": reciprocal(0.001, 0.1), \"C\": uniform(1, 10)}\n",
    "rbf_svr_rd_search_cv = RandomizedSearchCV(SVR(kernel='rbf', max_iter=50000), params,  cv=3, \n",
    "                                           scoring=\"neg_mean_squared_error\", random_state=42, n_jobs=-1)\n",
    "rbf_svr_rd_search_cv.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QRfd0uNsKANk",
    "outputId": "0bfeed0a-38bb-4730-c8b5-8dfc5f5487f6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters are: SVR(C=4.745401188473625, gamma=0.07969454818643928, max_iter=50000)\n"
     ]
    }
   ],
   "source": [
    "print(\"Best hyperparameters are:\", rbf_svr_rd_search_cv.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QniB-OTnKBpc",
    "outputId": "36de2278-4a96-4c44-8844-8e8c2f5eeaa0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE is: 13877012057.239176\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "print(\"MSE is:\",-rbf_svr_rd_search_cv.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "t-DWjFHGJwiU",
    "outputId": "96b0d554-bbcc-4735-a397-fcaca67d6d85"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=3, estimator=SVR(kernel='sigmoid'), n_jobs=-1,\n",
       "                   param_distributions={'C': <scipy.stats._distn_infrastructure.rv_frozen object at 0x7f0cc7d27250>,\n",
       "                                        'gamma': <scipy.stats._distn_infrastructure.rv_frozen object at 0x7f0cc7d27090>},\n",
       "                   random_state=42, return_train_score=True,\n",
       "                   scoring='neg_mean_squared_error')"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVR\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats import reciprocal, uniform\n",
    "\n",
    "params = {\"gamma\": reciprocal(0.001, 0.1), \"C\": uniform(1, 10)}\n",
    "sig_svr_rd_search_cv = RandomizedSearchCV(SVR(kernel='sigmoid'), params, n_iter=10, cv=3, \n",
    "                                           scoring=\"neg_mean_squared_error\",return_train_score=True,random_state=42, n_jobs=-1)\n",
    "sig_svr_rd_search_cv.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DL8qXxGAKJvV",
    "outputId": "a0aa1d88-cb12-440c-f5cc-b9ceac0cfbaf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters are: SVR(C=4.745401188473625, gamma=0.07969454818643928, kernel='sigmoid')\n"
     ]
    }
   ],
   "source": [
    "print(\"Best hyperparameters are:\",sig_svr_rd_search_cv.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NIBKZzNWKLTs",
    "outputId": "a9bd4109-a41f-4ffc-9ada-45c9e0764c1a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE is: 13744315287.792427\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "print(\"MSE is:\", -sig_svr_rd_search_cv.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lZSMo1hmcWTV"
   },
   "source": [
    "**[Add your solution here]**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SVmK22B5cWTV"
   },
   "source": [
    "## (e) [2 marks]\n",
    "\n",
    "**Task:** Choose the best model in (d). Then for this model, evaluate the RMSE on the test set, which is stored in `X_test` and `y_test`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zTg1dzmdRIg7"
   },
   "source": [
    "SVM regression with sigmoid kernel has lower mse and is therefore our best model.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qG0opFOuRWvp",
    "outputId": "76a518cd-d8d9-4c6c-a899-db30bcd6cdba"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "114741.28850451492"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "y_svr_pred_test = sig_svr_rd_search_cv.best_estimator_.predict(X_test)\n",
    "mse = mean_squared_error(y_test, y_svr_pred_test)\n",
    "\n",
    "np.sqrt(mse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0Ns3YfltcWTV"
   },
   "source": [
    "**[Add your solution here]**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I0XbisZFcWTW"
   },
   "source": [
    "# 3. Voting Classifiers [8 marks]\n",
    "## (a)  [4 marks]\n",
    "\n",
    "Consider the MNIST dataset. To save computational time, split it into a smaller training set (the first 5000 observations) and a validation set (the next 1000 observations) as given by the following code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "6LlfJf_ocWTW"
   },
   "outputs": [],
   "source": [
    "N = 5000\n",
    "M = 6000\n",
    "X_train = mnist[\"data\"][:N]\n",
    "X_val  = mnist[\"data\"][N:M]\n",
    "y_train = mnist[\"target\"][:N]\n",
    "y_val = mnist[\"target\"][N:M]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I4E69bvAcWTW"
   },
   "source": [
    "Do not shuffle the data and do not use a standard scaler. Train the following classifiers on the training set:\n",
    "\n",
    "(i) a random forest classifier with arguments `n_estimators=100, n_jobs=-1, random_state=42`,\n",
    "\n",
    "(ii) an extra-trees classifier with arguments `n_estimators=100, n_jobs=-1, random_state=42`,\n",
    "\n",
    "(iii) an AdaBoost classifier `n_estimators=50, learning_rate=0.2, random_state=42`,\n",
    "\n",
    "(iv) a gradient boosting classifier using the class `GradientBoostingClassifier()` with arguments `max_depth=2, n_estimators=10, learning_rate=0.25, random_state=42`.\n",
    "\n",
    "Report the accuracy of each trained classifier on the validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "R884O7E0XSH7",
    "outputId": "190b85e8-2a80-493b-917d-358823da8168"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy of RandomForestClassifier is:  0.939\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import  ExtraTreesClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "rndforest_clf = RandomForestClassifier(n_estimators=100, n_jobs=-1, random_state=42)\n",
    "rndforest_clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred_rndforest_clf_val = rndforest_clf.predict(X_val)\n",
    "print(\"accuracy of RandomForestClassifier is: \", accuracy_score(y_val, y_pred_rndforest_clf_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "C0ojdfFvYje9",
    "outputId": "bf7e0478-49c3-4112-a545-599f6c8655b6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy of ExtraTreesClassifier is:  0.947\n"
     ]
    }
   ],
   "source": [
    "extrees_clf = ExtraTreesClassifier(n_estimators=100, n_jobs=-1, random_state=42)\n",
    "extrees_clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred_extrees_clf_val = extrees_clf.predict(X_val)\n",
    "print(\"accuracy of ExtraTreesClassifier is: \", accuracy_score(y_val, y_pred_extrees_clf_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7-KoUac7Zrki",
    "outputId": "09317583-8221-438f-c4de-a58ab66e03a7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy of AdaBoostClassifier is:  0.736\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "ada_clf = AdaBoostClassifier(\n",
    "    DecisionTreeClassifier(max_depth=1), n_estimators=50,\n",
    "    algorithm=\"SAMME.R\", learning_rate=0.2, random_state=42)\n",
    "ada_clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred_adaclf_val = ada_clf.predict(X_val)\n",
    "print(\"accuracy of AdaBoostClassifier is: \", accuracy_score(y_val, y_pred_adaclf_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fNoP2zKRaHVa",
    "outputId": "dcf6d5d4-a716-457a-d90e-58d6e138829b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy of GradientBoostingClassifier is:  0.834\n"
     ]
    }
   ],
   "source": [
    "gb_clf = GradientBoostingClassifier(max_depth=2, n_estimators=10, learning_rate=0.25, random_state=42)\n",
    "gb_clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred_gb_clf_val = gb_clf.predict(X_val)\n",
    "print(\"accuracy of GradientBoostingClassifier is: \", accuracy_score(y_val, y_pred_gb_clf_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rbbQKpRRcWTX"
   },
   "source": [
    "**[Add your solution here]**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FQaqbCsccWTX"
   },
   "source": [
    "## (b)  [4 marks]\n",
    "Train a hard-voting and a soft-voting ensemble classifier based on the models in (a). Evaluate each voting classifier on the validation set. Comment on whether the performance of the ensemble model is better or worse than the individual models in (a) and why that is the case."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ximHa-D-cWTX"
   },
   "source": [
    "**[Add your solution here]**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NR6NEXPna_pX",
    "outputId": "c6bc7408-569d-404c-8028-263b4ff78118"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy of hard_voting_clf is:  0.923\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "classifers = [\n",
    "    (\"rndforest_clf\", rndforest_clf),\n",
    "    (\"extrees_clf\", extrees_clf),\n",
    "    (\"ada_clf\", ada_clf),\n",
    "    (\"gb_clf\", gb_clf),\n",
    "]\n",
    "hard_voting_clf = VotingClassifier(estimators=classifers, voting='hard')\n",
    "hard_voting_clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred_hard_voting_clf_val = hard_voting_clf.predict(X_val)\n",
    "print(\"accuracy of hard_voting_clf is: \", accuracy_score(y_val, y_pred_hard_voting_clf_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_Il9vmJZb_5w",
    "outputId": "d1ca51ee-7ea3-4f5c-dc18-1d98a80ba8cf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy of soft_voting_clf is:  0.926\n"
     ]
    }
   ],
   "source": [
    "soft_voting_clf = VotingClassifier(estimators=classifers, voting='soft')\n",
    "soft_voting_clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred_soft_voting_clf_val = soft_voting_clf.predict(X_val)\n",
    "print(\"accuracy of soft_voting_clf is: \", accuracy_score(y_val, y_pred_soft_voting_clf_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dy7Eb9ZvcrgM"
   },
   "source": [
    "2 of individual classifiers perform poorly wheres two are better than ensemble.\n",
    "\n",
    "Performance of hard-voting ensemble classifier is better than all individual classifiers except ExtraTreesClassifier and RandomForestClassifier. Hard-voting classifier takes majority voting across classifiers. It is possible that the one of the top performing classifiers namely ExtraTreesClassifier or RandomForestClassifer is wrong for same cases as other classifiers adversely affecting the majority vote.\n",
    "\n",
    "Performance of soft-voting ensemble classifier is better than all individual classifiers except ExtraTreesClassifier and RandomForestClassifier. Soft-voting classifier uses highest probability averaged over all individual classifiers. It is possible that the low performing classifier lower the average probability greatly leading to lower accuracy on the ensemble.\n",
    "\n",
    "Performance of soft-voting classifier is slightly better than that of hard-voting classifier. Averaging probabilites in soft-voting classifiers is beneficial but not too much as the lower performing individual classifiers are affecting accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FjVADiTpcWTY"
   },
   "source": [
    "# 4. Stacking [9 marks]\n",
    "\n",
    "We continue with the setting of Question 3. The training set, validation set and test set are the same. In Question 3, we have used predetermined rules (that is, hard-voting and soft-voting) to build the ensemble prediction. **Stacking** is an ensemble method in which you train a model (called a **blender**) to aggregate the result of each predictor into an ensemble prediction.\n",
    "\n",
    "Hint: Reading the subsection \"Stacking\" in Chapter 7 of the textbook and the solution to Question 9 in the Chapter 7 [Jupyter notebook](https://github.com/ageron/handson-ml2/blob/master/07_ensemble_learning_and_random_forests.ipynb) on the textbook website may help with this question.\n",
    "\n",
    "## (a)  [3 marks]\n",
    "\n",
    "For each of the four classifiers in Question 3(a), make 5000 clean predictions on the training set with 3-fold cross validation using `sklearn.model_selection.cross_val_predict()`. You should end up with four predictions per observation. Print at least the first 5 rows of `pred`. Next, apply one-hot encoding to `pred` since these predictions are class labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PEyj9HPI1px3",
    "outputId": "44cfcc8a-59dd-4a05-9f12-b8afd1bbefa5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5., 5., 3., 3.],\n",
       "       [0., 0., 5., 0.],\n",
       "       [4., 4., 4., 4.],\n",
       "       [1., 1., 1., 1.],\n",
       "       [9., 9., 9., 9.]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_predict\n",
    "estimators = [rndforest_clf, extrees_clf, ada_clf,  gb_clf]\n",
    "\n",
    "X_val_predictions = np.empty((len(X_train), len(estimators)))\n",
    "\n",
    "for index, estimator in enumerate(estimators):\n",
    "    X_val_predictions[:, index] = cross_val_predict(estimator, X_train, y_train, cv=3)\n",
    "\n",
    "X_val_predictions[:5,]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_u6IKsCL9FDw",
    "outputId": "61717800-56cd-4178-bb05-bd05cd55aca5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [1., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 1., ..., 0., 0., 0.],\n",
       "       [0., 1., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 1., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "cat_encoder = OneHotEncoder()\n",
    "X_val_predictions_hot = cat_encoder.fit_transform(X_val_predictions)\n",
    "X_val_predictions_hot.toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ms9oI74ZcWTY"
   },
   "source": [
    "**[Add your solution here]**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CB7RnCbicWTZ"
   },
   "source": [
    "## (b) [3 marks]\n",
    "Use the predictions in (a) as features and the actual label of the observations as the target. Train a random forest classifier on the training set with the parameters `n_estimators=100, random_state=42`.  This classifier is a blender. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UpllXVoi-joG",
    "outputId": "023e8f99-a6bf-42f8-e08a-5c40651a8933"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(oob_score=True, random_state=42)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnd_forest_blender = RandomForestClassifier(n_estimators=100, oob_score=True, random_state=42)\n",
    "rnd_forest_blender.fit(X_val_predictions_hot, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hVHFcu4bcWTZ"
   },
   "source": [
    "**[Add your solution here]**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-RiPY1hIcWTZ"
   },
   "source": [
    "## (c) [3 marks]\n",
    "\n",
    "Obtain the predictions of the blender on the validation set by feeding predictions on the validation set from the four classifiers in Question 3(a) into the blender trained in Question 4(b). Do not retrain the blender. These are called stacking predictions. Report the accuracy of your stacking predictions on the validation set and compare this to the results in Question 3(b)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "lM_WrvpK_ufe"
   },
   "outputs": [],
   "source": [
    "X_val_predictions_val = np.empty((len(X_val), len(estimators)), dtype=np.float32)\n",
    "\n",
    "for index, estimator in enumerate(estimators):\n",
    "    X_val_predictions_val[:, index] = estimator.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7jXG9jA6ACNs",
    "outputId": "c23e5bc0-bde5-423a-f013-783c63ea7db5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.947"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "cat_encoder = OneHotEncoder()\n",
    "X_val_predictions_val_hot = cat_encoder.fit_transform(X_val_predictions_val)\n",
    "\n",
    "y_pred = rnd_forest_blender.predict(X_val_predictions_val_hot)\n",
    "accuracy_score(y_val, y_pred)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EzeY5B0WFb6_"
   },
   "source": [
    "This is better than the voting classifer and equal to the best individual classifer (ExtraTreesClassifier)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rsbejEHfcWTZ"
   },
   "source": [
    "**[Add your solution here]**"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "RohanTiwari_CFRM521_Homework2.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": false,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
